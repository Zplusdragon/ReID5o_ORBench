# ReID5o_ORBench
<div align="center"><img src="Figures/ORBench.pdf" width="900"></div>

We investigate a new challenging problem called **Omni Multi-modal Person Re-identification** (OM-ReID), which aims to achieve effective retrieval with varying multi-modal queries. 

To address dataset scarcity, we construct **ORBench**, the first high-quality multi-modal dataset comprising 1,000 unique identities across five modalities: RGB, infrared, color pencil, sketch, and textual description. Moreover, we propose **ReID5o**, a novel multi-modal learning framework for person ReID. It enables synergistic fusion and cross-modal alignment of arbitrary modality combinations in a single model. 

More details can be found at our paper [ReID5o: Achieving Omni Multi-modal Person Re-identification in a Single Model](https://arxiv.org/abs/2312.03441).

## News
* ðŸ”¥[2025.6.12] We are hosting the Omni-Modality Person Re-Identification Challenge at PRCV2025 using ORBench. With generous prizes, everyone is welcome to participate!
* ðŸ”¥[2025.6.12] The paper is released.
  
## ORBench

## ReID5o
The ReID5o code and model will be made publicly available after the paper is accepted. Stay tuned!


